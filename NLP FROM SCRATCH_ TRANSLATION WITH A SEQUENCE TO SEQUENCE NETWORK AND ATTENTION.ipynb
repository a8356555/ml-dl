{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NLP FROM SCRATCH: TRANSLATION WITH A SEQUENCE TO SEQUENCE NETWORK AND ATTENTION","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN8Vcmrsl69QTI/WoEmxG1Z"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"oRZnVryBnDUX","colab_type":"text"},"source":["* re.sub(pattern, replace, str) replace pattern in str with replace\n","* \\1 stands for group\n","* reversed()\n","* softmax for n>2；sigmoid for n = 2\n","* embedding 需先預設n個字x k個維度,經過embedding曾後會把傳進的input轉換，input若有15個值代表有15個字，則embeddin會輸出15x256的向量"]},{"cell_type":"code","metadata":{"id":"vSoQhNDtPmvr","colab_type":"code","cellView":"both","colab":{}},"source":["from __future__ import unicode_literals, print_function, division\n","from io import open\n","import unicodedata, string, re, random\n","\n","import torch\n","import torch.nn as nn\n","from torch import optim\n","import torch.nn.functional as F\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g3I-yQxlQW6p","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":122},"executionInfo":{"status":"ok","timestamp":1597471393199,"user_tz":-480,"elapsed":33977,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"b3656028-7ec2-4420-a675-dcc8b4d99a6c"},"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")\n","#4/3AHP6U4aofsRnDIA8xLWRBFyt9cXwpvgAoXJ5S0I8VZIrhMxQz-JW-A"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ELbTzQnu7nE","colab_type":"code","cellView":"both","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1597471405753,"user_tz":-480,"elapsed":2164,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"354c4611-47b6-4826-b066-0e3687a8f559"},"source":["import os\n","all_files =  os.walk('/content')\n","for _ in all_files:\n","  if '%s-%s.txt' % ('eng', 'fra') in _[2]:\n","    print('%s/%s' % (_[0],_[2][_[2].index('%s-%s.txt' % ('eng', 'fra'))]))\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/space_Colab/data/data/eng-fra.txt\n","/content/drive/My Drive/space_Colab/data_lang/data/eng-fra.txt\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"a9xQ8MbvRJLI","colab_type":"code","cellView":"both","colab":{}},"source":["SOS_token = 0\n","EOS_token = 1\n","\n","class Lang:\n","    def __init__(self, name):\n","        self.name = name\n","        self.word2index = {}\n","        self.word2count = {}\n","        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n","        self.n_words = 2  # Count SOS and EOS\n","\n","    def addSentence(self, sentence):\n","        for word in sentence.split(' '):\n","            self.addWord(word)\n","\n","    def addWord(self, word):\n","        if word not in self.word2index:\n","            self.word2index[word] = self.n_words\n","            self.word2count[word] = 1\n","            self.index2word[self.n_words] = word\n","            self.n_words += 1\n","        else:\n","            self.word2count[word] += 1\n","\n","    #word2index \"wordA\":index 第幾個加入\n","    #word2count \"wordA\":count_nums 出現次數\n","    #index2word index: \"Word\""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5Y6PjXBSd7t","colab_type":"code","cellView":"both","colab":{}},"source":["# Turn a Unicode string to plain ASCII, thanks to\n","# https://stackoverflow.com/a/518232/2809427\n","def unicodeToAscii(s):\n","    return ''.join(\n","        c for c in unicodedata.normalize('NFD', s)\n","        if unicodedata.category(c) != 'Mn'\n","    )\n","\n","# Lowercase, trim, and remove non-letter characters\n","\n","\n","def normalizeString(s):\n","    s = unicodeToAscii(s.lower().strip())\n","    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n","    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n","    return s"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zvzsGutOT8Wl","colab_type":"code","cellView":"both","colab":{}},"source":["def readLangs(lang1, lang2, reverse=False):\n","    print(\"Reading lines...\")\n","\n","    # Read the file and split into lines\n","    lines = open('/content/drive/My Drive/space_Colab/data_lang/data/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n","        read().strip().split('\\n')\n","\n","    # Split every line into pairs and normalize\n","    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n","\n","    # Reverse pairs, make Lang instances\n","    if reverse:\n","        pairs = [list(reversed(p)) for p in pairs]\n","        input_lang = Lang(lang2)\n","        output_lang = Lang(lang1)\n","    else:\n","        input_lang = Lang(lang1)\n","        output_lang = Lang(lang2)\n","\n","    return input_lang, output_lang, pairs\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y7VvZZWuVx6j","colab_type":"code","colab":{}},"source":["MAX_LENGTH = 10\n","\n","eng_prefixes = (\n","    \"i am \", \"i m \",\n","    \"he is\", \"he s \",\n","    \"she is\", \"she s \",\n","    \"you are\", \"you re \",\n","    \"we are\", \"we re \",\n","    \"they are\", \"they re \"\n",")\n","\n","\n","def filterPair(p):\n","    return len(p[0].split(' ')) < MAX_LENGTH and \\\n","        len(p[1].split(' ')) < MAX_LENGTH and \\\n","        p[1].startswith(eng_prefixes)\n","\n","\n","def filterPairs(pairs):\n","    return [pair for pair in pairs if filterPair(pair)]"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"K3u1Iq7LjtDQ","colab_type":"text"},"source":["The full process for preparing the data is:\n","\n","*   Read text file and split into lines, split lines into pairs\n","*   Normalize text, filter by length and content\n","*   Make word lists from sentences in pairs"]},{"cell_type":"code","metadata":{"id":"gfKdYp0mje6_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1597471597495,"user_tz":-480,"elapsed":5756,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"d415de75-ca7f-4795-bbfd-c3316d14fac9"},"source":["def prepareData(lang1, lang2, reverse=False):\n","    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n","    print(\"Read %s sentence pairs\" % len(pairs))\n","    pairs = filterPairs(pairs)\n","    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n","    print(\"Counting words...\")\n","    for pair in pairs:\n","        input_lang.addSentence(pair[0])\n","        output_lang.addSentence(pair[1])\n","    print(\"Counted words:\")\n","    print(input_lang.name, input_lang.n_words)\n","    print(output_lang.name, output_lang.n_words)\n","    return input_lang, output_lang, pairs\n","\n","\n","input_lang, output_lang, pairs = prepareData('eng', 'fra', True)\n","print(random.choice(pairs))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading lines...\n","Read 135842 sentence pairs\n","Trimmed to 10599 sentence pairs\n","Counting words...\n","Counted words:\n","fra 4345\n","eng 2803\n","['tu es fatigue et moi aussi .', 'you are tired and so am i .']\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RphbwUH2rGOh","colab_type":"code","colab":{}},"source":["class EncoderRNN(nn.Module):\n","  def __init__(self, input_size, hidden_size):#(4543,256)\n","    super(EncoderRNN, self).__init__()\n","    self.hidden_size = hidden_size #256\n","\n","    self.embedding = nn.Embedding(input_size, hidden_size) #參數1:size of dict(有input_size個字),參數2:size of each vector(每個字有hidden_size個特徵/維度)\n","                    #4543字x256維\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","    # gru: gated recurrent units\n","    # 輸出output 及n秒以後的 h_n(output為hidden_t的維度變換，若為雙向則output_size = 字數x 常數 x hidden_size*2)\n","    # 參數:(input_size, hidden_size)\n","  def forward(self, input, hidden): #hidden(1x1x hidden_size) 1x1x256\n","    #input:一個字 size(1x1), value(word對應的index)\n","    #1x input_size to 1x input_size x hidden_size to 1x1x flattened(input_size*hidden_size)\n","    #embedding後變成1x256維的向量 然後再view=> 1x1x256\n","    embedded = self.embedding(input).view(1,1,-1) \n","    output = embedded #1x1x 256\n","    output,hidden = self.gru(output, hidden) #輸出output 1x1x256, hidden 1x1x256\n","    return output, hidden\n","\n","  def initHidden(self):\n","    return torch.zeros(1,1,self.hidden_size, device=device) #1x1x hidden_size\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LC-Ah3hqsF0I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597471615773,"user_tz":-480,"elapsed":740,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"ca0893ff-ff96-44a6-8d06-b754af743373"},"source":["input = torch.randn(1, 3, 3)\n","# input = input.view(1,1,-1)\n","# input = input.unsqueeze(0)\n","input.size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 3, 3])"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"ZQSHljJFrVrA","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597471634435,"user_tz":-480,"elapsed":752,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"fe1d4b9f-81b0-4894-cd8c-7f9760fbd37c"},"source":["rnn = nn.GRU(10, 10)\n","input = torch.randn(1, 1, 10)\n","h0 = torch.randn(1, 1, 10)\n","output, hn = rnn(input, h0)\n","output.size(),hn.size()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(torch.Size([1, 1, 10]), torch.Size([1, 1, 10]))"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"JZbDK7eIss3S","colab_type":"code","colab":{}},"source":["class DecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size):\n","    super(DecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.embedding = nn.Embedding(output_size, hidden_size)\n","    #embedding的參數(num_embeddings, embedding_dim)：\n","    # size of the dictionary of embeddings， the size of each embedding vector\n","    self.gru = nn.GRU(hidden_size, hidden_size)\n","    self.out = nn.Linear(hidden_size, output_size)\n","    self.softmax = nn.LogSoftmax(dim=1)\n","\n","  def forward(self, input, hidden):\n","    output = self.embedding(input).view(1,1,-1) #1x1x flattened(output_size*hidden_size)\n","    output = F.relu(output)\n","    output, hidden = self.gru(output, hidden)\n","    output = self.softmax(self.out(output[0]))\n","    return output, hidden\n","#output[0]?\n","  \n","  def initHidden(self):\n","    return torch.zeros(1,1,self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"q1ydpbcP6BXH","colab_type":"code","colab":{}},"source":["class AttnDecoderRNN(nn.Module):\n","  def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n","    super(AttnDecoderRNN, self).__init__()\n","    self.hidden_size = hidden_size\n","    self.output_size = output_size\n","    self.dropout_p = dropout_p\n","    self.max_length = max_length\n","\n","    self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n","    #英文2803個字x256維\n","    #參數1:size of dict(有output_size個字),參數2:size of each vector(每個字有hidden_size個特徵/維度)\n","    self.attn = nn.Linear(self.hidden_size*2, self.max_length) #?x?x 512 to ?x?x 10\n","    self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n","    self.dropout = nn.Dropout(self.dropout_p)\n","    self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n","    self.out = nn.Linear(self.hidden_size, self.output_size)\n","\n","  def forward(self, input, hidden, encoder_outputs): #第一個input：1x1； hidden：1x1xhidden, encoder_outputs：10xhidden_size\n","    #input:一個字 size(1x1), value(word對應的index)\n","    #embedding後變成1x256維的向量 然後再view=> 1x1x256\n","    embedded = self.embedding(input).view(1,1,-1) #1x1x 256 \n","    embedded = self.dropout(embedded)\n","\n","    attn_weights = F.softmax(self.attn(torch.cat((embedded[0], hidden[0]), 1)), dim=1) #embedded[0]代表(1x1x256=>1x256)，故 1x256 cat 1x256 =>1x512 to 1x10\n","    attn_applied = torch.bmm(attn_weights.unsqueeze(0), encoder_outputs.unsqueeze(0))  #unsqueeze(0)在index=0的維度插入1：[3,3] => [1,3,3]\n","                # 1x1x10 & 1x10x256 => 1x1x256\n","    output = torch.cat((embedded[0], attn_applied[0]), 1) #1x256 cat 1x256 = 1x512 \n","    output = self.attn_combine(output).unsqueeze(0)     #1x512 => 1x256 .unsqueeze(0) => 1x1x256\n","\n","    output = F.log_softmax(self.out(output[0]), dim=1)   #1x256 => 1x2803 每個字的機率\n","    # print(output)\n","    return output, hidden, attn_weights\n","\n","  def initHidden(self):\n","    return torch.zeros(1, 1, self.hidden_size, device=device)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L8INMhrj_PGh","colab_type":"code","colab":{}},"source":["def indexesFromSentence(lang, sentence):\n","  return [lang.word2index[word] for word in sentence.split(' ')]\n","\n","def tensorFromSentence(lang, sentence):\n","  indexes = indexesFromSentence(lang, sentence)\n","  indexes.append(EOS_token)\n","  return torch.tensor(indexes, dtype = torch.long, device = device).view(-1,1)\n","  # nx1\n","def tensorsFromPair(pair):\n","  input_tensor = tensorFromSentence(input_lang, pair[0])\n","  target_tensor = tensorFromSentence(output_lang, pair[1])\n","  return (input_tensor, target_tensor)\n","  #input_tensor:[[1],[5],...,[1]]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"H2eHNIUvBXdt","colab_type":"code","colab":{}},"source":["teacher_forcing_ratio = 0.5\n","\n","def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer,\n","          decoder_optimizer, criterion, max_length=MAX_LENGTH):\n","  encoder_hidden = encoder.initHidden()\n","\n","  encoder_optimizer.zero_grad()\n","  decoder_optimizer.zero_grad()\n","\n","  input_length = input_tensor.size(0) #size(0)：第一個維度，表示有幾個字\n","  target_length = target_tensor.size(0)\n","\n","  encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device = device)\n","  # 10 x 256 (10個字，每個字用256維表示)\n","  loss = 0\n","\n","  for ei in range(input_length):\n","    encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden) #input_tensor[ei]表示只傳一個字的index進去 size(1x1)\n","    encoder_outputs[ei] = encoder_output[0,0] #[0,0]表示從1x1x256變成1x256\n","\n","  decoder_input = torch.tensor([[SOS_token]], device=device) #1x1 value = 0\n","\n","  decoder_hidden = encoder_hidden\n","\n","  use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n","\n","  if use_teacher_forcing:\n","    # Teacher forcing: Feed the target as the next input\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","      #1x2803(個字)的向量, 1x256, 1x10(每句十個字)\n","      # print(decoder_output, target_tensor[di])\n","      loss += criterion(decoder_output, target_tensor[di]) #size(1xn) size(1x1) 會從前面一維長向量裡面找出index=後方值的該值\n","      decoder_input = target_tensor[di]\n","\n","  else:\n","    for di in range(target_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","      topv,topi = decoder_output.topk(1)\n","      decoder_input = topi.squeeze().detach()#?\n","      # print(decoder_output, target_tensor[di])\n","      loss += criterion(decoder_output, target_tensor[di])\n","      if decoder_input.item() == EOS_token:\n","        break\n","  loss.backward()\n","\n","  encoder_optimizer.step()\n","  decoder_optimizer.step()\n","\n","  return loss.item()/target_length\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VPiAxRuCvM7H","colab_type":"code","colab":{}},"source":["# hidden_size = 256\n","# learning_rate=0.005\n","# encoder = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","# decoder = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","# encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","# decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","# training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(10)]\n","# criterion = nn.NLLLoss()\n","\n","# iter=1\n","# training_pair = training_pairs[iter-1]\n","# input_tensor = training_pair[0]\n","# target_tensor = training_pair[1]\n","\n","# # target_tensor\n","# loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rF8WFfG-4Aoj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1597390197295,"user_tz":-480,"elapsed":633,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"a2e26f32-91df-48f2-ecb2-f645390506c3"},"source":["torch.tensor([[SOS_token]], device=device)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[0]])"]},"metadata":{"tags":[]},"execution_count":41}]},{"cell_type":"code","metadata":{"id":"8Q8omlUq5O0a","colab_type":"code","colab":{}},"source":["import time, math\n","\n","def asMinutes(s):\n","  m=math.floor(s/60)\n","  s -= m*60\n","  return '%dm %ds' %(m, s)\n","\n","def timeSince(since, percent):\n","  now = time.time()\n","  s = now - since\n","  es = s/(percent)\n","  re = es - s\n","  return '%s (-%s)' % (asMinutes(s), asMinutes(re))\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZHFkTuOa59up","colab_type":"code","colab":{}},"source":["def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n","  start = time.time()\n","  plot_losses = []\n","  print_loss_total = 0 #Reset every print_every\n","  plot_loss_total = 0 #Reset evry\n","  \n","  encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n","  decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n","  training_pairs = [tensorsFromPair(random.choice(pairs)) for i in range(n_iters)]\n","  criterion = nn.NLLLoss() #第一個參數必為一維長向量(1xn)，第二個參數為1x1的值(該值對應為前方長向量的index) \n","\n","  for iter in range(1, n_iters + 1):\n","    training_pair = training_pairs[iter-1]\n","    input_tensor = training_pair[0]\n","    target_tensor = training_pair[1]\n","\n","    loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n","    print_loss_total += loss\n","    plot_loss_total += loss\n","\n","    if iter%print_every == 0:\n","      print_loss_avg = print_loss_total/print_every\n","      print_loss_total = 0\n","      print('%s(%d %d%%) %.4f' %(timeSince(start, iter/n_iters), iter, iter/n_iters*100, print_loss_avg))\n","\n","    if iter%plot_every ==0:\n","      plot_loss_avg = plot_loss_total/ plot_every\n","      plot_losses.append(plot_loss_avg)\n","      plot_loss_total = 0\n","\n","  showPlot(plot_losses)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oZYIGour77RP","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","plt.switch_backend('agg')\n","import matplotlib.ticker as ticker\n","import numpy as np\n","\n","\n","def showPlot(points):\n","  plt.figure()\n","  fig, ax = plt.subplots()\n","  # this locator puts ticks at regular intervals\n","  loc = ticker.MultipleLocator(base=0.2)\n","  ax.yaxis.set_major_locator(loc)\n","  plt.plot(points)\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ShmOD67r8dD_","colab_type":"code","colab":{}},"source":["def evaluate(encoder, decoder, sentence, max_length = MAX_LENGTH):\n","  with torch.no_grad():\n","    input_tensor = tensorFromSentence(input_lang, sentence)\n","    input_length = input_tensor.size()[0]\n","    encoder_hidden = encoder.initHidden()\n","\n","    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n","\n","    for ei in range(input_length):\n","      encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n","      encoder_outpus[ei] += encoder_output[0,0]\n","    \n","    decoder_input = torch.tensor([[SOS_token]], device = device)\n","    decoder_hidden = encoder_hidden\n","\n","    decoded_words = []\n","    decoder_attentions = torch.zeros(max_length, max_length)\n","\n","    for di in range(max_length):\n","      decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n","      decoder_attentions[di] = decoder_attention.data\n","      topv, topi = decoder_output.data.topl(1)\n","      if topi.item() == EOS_token:\n","        decoded_words.append('<EOS>')\n","        break\n","      else:\n","        decoded_words.append(output_lang.index2word[topi.item()])\n","\n","      decoder_input = topi.squeeze().detach()\n","\n","    return decoded_words, decoder_attentions[:di+1]\n","    "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UqUysmCP-hBV","colab_type":"code","colab":{}},"source":["def evaluateRandomly(encoder, decoder, n=10):\n","  for i in range(n):\n","    pair = random.choice(pairs)\n","    print('>', pair[0])\n","    print('=', pair[1])\n","    output_words, attentions = evaluate(encoder, decoder, pair[0])\n","    output_sentence = ' ',join(output_words)\n","    print('<', output_sentence)\n","    print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MHnJxI_G_bUU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"executionInfo":{"status":"ok","timestamp":1597398044154,"user_tz":-480,"elapsed":3789237,"user":{"displayName":"黃鈺倫 Intern","photoUrl":"","userId":"07415287677551779104"}},"outputId":"635a7808-6ab1-439a-a120-bdbf0183ec5d"},"source":["hidden_size = 256\n","encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n","attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n","\n","trainIters(encoder1, attn_decoder1, 75000, print_every=5000)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["4m 17s (-60m 11s)(5000 6%) 2.8812\n","8m 30s (-55m 17s)(10000 13%) 2.4179\n","12m 41s (-50m 44s)(15000 20%) 2.1703\n","16m 53s (-46m 27s)(20000 26%) 2.0507\n","21m 8s (-42m 17s)(25000 33%) 1.9702\n","25m 23s (-38m 4s)(30000 40%) 1.9080\n","29m 35s (-33m 48s)(35000 46%) 1.8653\n","33m 46s (-29m 33s)(40000 53%) 1.8171\n","37m 58s (-25m 19s)(45000 60%) 1.8232\n","42m 11s (-21m 5s)(50000 66%) 1.8266\n","46m 23s (-16m 52s)(55000 73%) 1.8782\n","50m 34s (-12m 38s)(60000 80%) 1.8561\n","54m 44s (-8m 25s)(65000 86%) 1.8575\n","58m 56s (-4m 12s)(70000 93%) 1.8770\n","63m 7s (-0m 0s)(75000 100%) 1.9273\n"],"name":"stdout"}]}]}
